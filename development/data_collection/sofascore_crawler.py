import pandas as pdimport reimport timeimport osfrom bs4 import BeautifulSoupfrom datetime import datetime, timedeltafrom selenium import webdriverfrom webdriver_manager.chrome import ChromeDriverManagerfrom crawler import scrap_sofascoredef initialize(url, load_sleep=10):    driver = webdriver.Chrome(ChromeDriverManager().install())    driver.get(url)    time.sleep(load_sleep)  # to let the HTML load    return driverdef clean(s):    s = re.sub('\n','',s)    return sdef reshaping(home, i, away): # list of 3: [stat, incident, stat]    i = i.lower()    return {i+'_h': home, i+'_a': away}def scrap_stat(driver, event_id):    # get timer    timer = scrap_sofascore(driver)    # get stat data    stat_all = driver.find_element_by_id('statistics-period-ALL')    soup = BeautifulSoup(stat_all.get_attribute('innerHTML'),'html.parser')    content = [clean(x).strip() for x in soup.find_all(text=True) if x != '\n']    iterator = iter(content)    df_dict = {'event_id': event_id,                'timestamp': datetime.strftime(datetime.now(),'%Y-%m-%d %H:%M:%S'),                'timer': timer}    for i in iterator:        df_dict.update(reshaping(i, next(iterator), next(iterator)))    df = pd.DataFrame(df_dict, index=[0])    return dfdef get_sofascore_stat(driver, sofascore_url, event_id):        stats = scrap_stat(driver, event_id)    if os.path.exists('data_sofascore_stat/{}_stat.csv'.format(event_id)) == True:        df = pd.read_csv('data_sofascore_stat/{}_stat.csv'.format(event_id))        df = df.append(stats)        df.to_csv('data_sofascore_stat/{}_stat.csv'.format(event_id), index=False, mode='w', header=True)    else:        stats.to_csv('data_sofascore_stat/{}_stat.csv'.format(event_id), index=False, mode="w", header=True)    if __name__ == '__main__':    event_id = '20200311WED2'    #------------------------------    # get url from schedule.csv according to event_id given above    schedule = pd.read_csv("data/schedule.csv")    game_info = schedule[schedule['event_id'] == event_id].iloc[-1,]    sofascore_url = game_info['sofascore_url']    driver = initialize(sofascore_url)    get_sofascore_stat(driver, sofascore_url, event_id)    while(True):        try:            get_sofascore_stat(driver, sofascore_url, event_id)        except:            pass        print('Finished crawling. Crawl again in 10 seconds.')        time.sleep(10)